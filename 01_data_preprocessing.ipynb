{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the distribution of class in all csv files (Lake SIMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Calanoid_1       215214\n",
      "Cyclopoid_1      197982\n",
      "Bosmina_1          2875\n",
      "Herpacticoida       607\n",
      "Daphnia             558\n",
      "Chydoridae           43\n",
      "Chironomid           38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory containing CSV files\n",
    "csv_dir = \"SIMC_OverlapTiffsWithPP/SIMC.Overlap.csv\"  \n",
    "\n",
    "# Define the target zooplankton classes (The 7 classes that the government cares about.)\n",
    "target_classes = [\"Calanoid_1\", \"Cyclopoid_1\", \"Bosmina_1\", \"Herpacticoida\", \"Chironomid\", \"Chydoridae\", \"Daphnia\"]\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSV files\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, usecols=[\"Class\"])  \n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "# Count occurrences of each target zooplankton class\n",
    "class_counts = all_data[\"Class\"].value_counts()\n",
    "\n",
    "# Filter only the target classes\n",
    "filtered_counts = class_counts[class_counts.index.isin(target_classes)]\n",
    "\n",
    "print(filtered_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calanoid and Cyclopoid copepods are two of the most ecologically significant and abundant groups of zooplankton.\n",
    "Considering the computing power and the resources available, a binary classification model for these two classes is possible to develop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "Takes about 1.5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Filter and save Calanoid and Cyclopoid data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Filter and Save Calanoid and Cyclopoid data...\n",
      "Step 1 Complete: Filtered data saved to 'filtered_zooplankton_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"Step 1: Filter and Save Calanoid and Cyclopoid data...\")\n",
    "\n",
    "csv_dir = \"SIMC_OverlapTiffsWithPP/SIMC.Overlap.csv\"  \n",
    "filtered_output = \"filtered_zooplankton_data.csv\"  \n",
    "final_output = \"merged_filtered_zooplankton_data.csv\"  \n",
    "\n",
    "# Define the target zooplankton classes (Only look at two classes.)\n",
    "target_classes = [\"Calanoid_1\", \"Cyclopoid_1\"]\n",
    "\n",
    "filtered_data = []\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
    "\n",
    "# Read and filter all CSV files\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)  \n",
    "    df_filtered = df[df[\"Class\"].isin(target_classes)].copy()  \n",
    "    if not df_filtered.empty:\n",
    "        df_filtered.loc[:, \"source_file\"] = os.path.basename(file)  # add source file column for merge environmental facdtors\n",
    "        filtered_data.append(df_filtered)  \n",
    "\n",
    "if filtered_data:\n",
    "    final_data = pd.concat(filtered_data, ignore_index=True)\n",
    "    final_data.to_csv(filtered_output, index=False)\n",
    "    print(f\"Step 1 Complete: Filtered data saved to '{filtered_output}'.\")\n",
    "else:\n",
    "    print(\"Step 1 Warning: No matching data found in the CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess MasterTable (Remove Duplicates & Filter SIMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Preprocessing MasterTable...\n",
      "Step 2 Complete: MasterTable filtered and deduplicated. Remaining rows: 236\n"
     ]
    }
   ],
   "source": [
    "master_table_path = \"MasterTable_AI_FlowCAM.xlsx\"  \n",
    "\n",
    "print(\"Step 2: Preprocessing MasterTable...\")\n",
    "\n",
    "# Load the MasterTable (environmental data)\n",
    "master_table = pd.read_excel(master_table_path)\n",
    "\n",
    "# Ensure consistent column formatting\n",
    "master_table.rename(columns=lambda x: x.strip().lower(), inplace=True)\n",
    "master_table[\"csvfile\"] = master_table[\"csvfile\"].astype(str)\n",
    "\n",
    "# Filter MasterTable to keep only rows where 'csvfile' contains 'SIMC'\n",
    "master_table = master_table[master_table[\"csvfile\"].str.contains(\"SIMC\", na=False, case=False)]\n",
    "\n",
    "# Drop duplicates based on 'csvfile' column\n",
    "master_table = master_table.drop_duplicates(subset=[\"csvfile\"])\n",
    "\n",
    "print(f\"Step 2 Complete: MasterTable filtered and deduplicated. Remaining rows: {len(master_table)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Merge filtered data with preprocessed MasterTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Merging filtered data with MasterTable...\n",
      "Step 3 Complete: Merged data saved to 'merged_filtered_zooplankton_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Merging filtered data with MasterTable...\")\n",
    "\n",
    "filtered_df = pd.read_csv(filtered_output)\n",
    "\n",
    "filtered_df[\"source_file\"] = filtered_df[\"source_file\"].astype(str)\n",
    "\n",
    "# Merge based on 'source_file' (filtered_df) and 'csvfile' (MasterTable)\n",
    "merged_df = filtered_df.merge(master_table, left_on=\"source_file\", right_on=\"csvfile\", how=\"left\")\n",
    "\n",
    "merged_df.to_csv(final_output, index=False)\n",
    "\n",
    "print(f\"Step 3 Complete: Merged data saved to '{final_output}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality check for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Biovolume..Cylinder.</td>\n",
       "      <td>397474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Biovolume..P..Spheroid.</td>\n",
       "      <td>397474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Biovolume..Sphere.</td>\n",
       "      <td>397474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>tifffile</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>csvfile</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>year</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>sam</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>month</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>day</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>rep</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>repnum</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>key</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>loc</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>site</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>doy</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>gdd2</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>watert</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>lat0</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>lat1</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>lon0</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>lon1</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>avgdepth</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>trawltime</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>effspeed</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>mindepth</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>maxdepth</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>xangle</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>precip</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>xwaveht</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>wind</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cloud_pc</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>distshore</td>\n",
       "      <td>69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>fr</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>volbest</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>whitefishden</td>\n",
       "      <td>25379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>unknwcoregonine</td>\n",
       "      <td>25379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ciscoden</td>\n",
       "      <td>25379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>exposure</td>\n",
       "      <td>30035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>smeltden</td>\n",
       "      <td>413196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>yperchden</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>burbotden</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>otherfishden</td>\n",
       "      <td>18933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  null_count\n",
       "58     Biovolume..Cylinder.      397474\n",
       "59  Biovolume..P..Spheroid.      397474\n",
       "60       Biovolume..Sphere.      397474\n",
       "61                 tifffile       18933\n",
       "62                  csvfile       18933\n",
       "63                     year       18933\n",
       "64                      sam       18933\n",
       "65                    month       18933\n",
       "66                      day       18933\n",
       "67                      rep       18933\n",
       "68                   repnum       18933\n",
       "69                      key       18933\n",
       "70                      loc       18933\n",
       "71                     site       18933\n",
       "72                      doy       18933\n",
       "73                     gdd2       18933\n",
       "74                   watert       18933\n",
       "75                     lat0       18933\n",
       "76                     lat1       18933\n",
       "77                     lon0       18933\n",
       "78                     lon1       18933\n",
       "79                 avgdepth       18933\n",
       "80                trawltime       18933\n",
       "81                 effspeed       18933\n",
       "82                 mindepth       18933\n",
       "83                 maxdepth       18933\n",
       "84                   xangle       18933\n",
       "85                   precip       18933\n",
       "86                  xwaveht       18933\n",
       "87                     wind       18933\n",
       "88                 cloud_pc       18933\n",
       "89                distshore       69107\n",
       "90                       fr       18933\n",
       "91                  volbest       18933\n",
       "92             whitefishden       25379\n",
       "93          unknwcoregonine       25379\n",
       "94                 ciscoden       25379\n",
       "95                 exposure       30035\n",
       "96                 smeltden      413196\n",
       "97                yperchden       18933\n",
       "98                burbotden       18933\n",
       "99             otherfishden       18933"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of missing values for each column\n",
    "t = merged_df.isna().sum().reset_index(name=\"null_count\")\n",
    "t[t['null_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20190617_SIMC_238_2mm_rep2_AD_data.csv',\n",
       "       '20190506_SIMC_017_2mm_rep2_AD_data.csv',\n",
       "       '20190611_SIMC_218_2mm_rep4_AD_data.csv',\n",
       "       '20170510_SIMC_095_2mm_rep2_KG_data.csv',\n",
       "       '20170608_SIMC_177_2mm_rep3_KG_data.csv',\n",
       "       '20170523_SIMC_133_2mm_rep3_redo_KG_data.csv',\n",
       "       '20190508_SIMC_047_2mm_rep1_KG_data.csv',\n",
       "       '20170510_SIMC_095_2mm_rep1_KG_data.csv',\n",
       "       '20170523_SIMC_133_2mm_rep2_redo_KG_data.csv',\n",
       "       '20170608_SIMC_179_2mm_rep3_KG_data.csv',\n",
       "       '20190506_SIMC_017_2mm_rep3_KG_data.csv',\n",
       "       '20190508_SIMC_047_2mm_rep2_AD_data.csv',\n",
       "       '20170608_SIMC_177_2mm_rep2_KG_data.csv',\n",
       "       '20190507_SIMC_033_2mm_rep3_AD_data.csv',\n",
       "       '20170608_SIMC_179_2mm_rep2_KG_data.csv'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['year'].isna()]['source_file'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environmental factors for these files are not available. So we exclude these data in the analysis. \\\n",
    "In total, exclude about 4.6% data (3.2% are Calanoid, 1.3% are Cyclopoid).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Calanoid_1     0.032299\n",
       "Cyclopoid_1    0.013521\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['year'].isna()]['Class'].value_counts() / len(merged_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
